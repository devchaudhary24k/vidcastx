import { relations } from "drizzle-orm";
import {
  boolean,
  index,
  integer,
  jsonb,
  pgEnum,
  pgTable,
  text,
  timestamp,
  vector,
} from "drizzle-orm/pg-core";

import { videos } from "./video-schema";

// Enums
export const transcriptStatusEnum = pgEnum("transcript_status", [
  "pending",
  "processing",
  "completed",
  "failed",
]);

// ============================================
// TRANSCRIPTS
// ============================================

/**
 * Full transcripts for videos - supports multiple languages
 */
export const transcripts = pgTable(
  "transcript",
  {
    id: text("id").primaryKey(), // NanoID
    videoId: text("video_id")
      .notNull()
      .references(() => videos.id, { onDelete: "cascade" }),

    language: text("language").default("en").notNull(), // ISO 639-1: 'en', 'es', 'fr'

    // Distinguish between the "Source Truth" and "Translations"
    isOriginal: boolean("is_original").default(true).notNull(),
    isAutoGenerated: boolean("is_auto_generated").default(true).notNull(),

    // Full transcript text (optimized for Full-Text Search via tsvector in Postgres)
    content: text("content").notNull(),

    // Timed segments for subtitle display (VTT format structure)
    // [{ start: 0.0, end: 2.5, text: "Hello world" }, ...]
    segments: jsonb("segments").default([]).notNull(),

    // Word-level timing for "TikTok Style" Karaoke captions
    // [{ word: "Hello", start: 0.0, end: 0.5, confidence: 0.98 }, ...]
    wordTimings: jsonb("word_timings").default([]),

    // Metadata
    status: transcriptStatusEnum("status").default("pending").notNull(),
    provider: text("provider"), // 'openai', 'deepgram', 'assembly'
    confidence: integer("confidence"), // Average confidence score 0-100
    durationProcessed: integer("duration_processed"), // Seconds of audio processed (for billing cross-check)
    errorLog: text("error_log"),

    createdAt: timestamp("created_at").defaultNow().notNull(),
    updatedAt: timestamp("updated_at")
      .defaultNow()
      .$onUpdate(() => new Date())
      .notNull(),

    // Soft Delete: Allow hiding a bad transcript without destroying the billing record
    deletedAt: timestamp("deleted_at"),
  },
  (table) => [
    index("transcript_videoId_idx").on(table.videoId),
    index("transcript_videoId_language_idx").on(table.videoId, table.language),
  ],
);

/**
 * Transcript segments with embeddings for semantic search
 * Enables "search for concepts" feature
 */
export const transcriptEmbeddings = pgTable(
  "transcript_embedding",
  {
    id: text("id").primaryKey(),
    transcriptId: text("transcript_id")
      .notNull()
      .references(() => transcripts.id, { onDelete: "cascade" }),
    videoId: text("video_id")
      .notNull()
      .references(() => videos.id, { onDelete: "cascade" }),

    // Segment info
    segmentIndex: integer("segment_index").notNull(),
    startTime: integer("start_time").notNull(), // milliseconds
    endTime: integer("end_time").notNull(), // milliseconds
    text: text("text").notNull(), // The chunk of text this vector represents

    // Vector embedding for semantic search
    // 1536 is for OpenAI `text-embedding-3-small`.
    // If you switch to open-source (e.g. all-MiniLM-L6-v2), change this to 384.
    embedding: vector("embedding", { dimensions: 1536 }),

    createdAt: timestamp("created_at").defaultNow().notNull(),
  },
  (table) => [
    index("embedding_transcriptId_idx").on(table.transcriptId),
    index("embedding_videoId_idx").on(table.videoId),
    // ⚠️ CRITICAL: In your migration SQL, you MUST run:
    // CREATE INDEX ON transcript_embedding USING hnsw (embedding vector_cosine_ops);
    // Drizzle cannot auto-generate HNSW indexes easily in schema definition yet.
  ],
);

// ============================================
// VIDEO CHAPTERS
// ============================================

/**
 * Timestamped chapters for video navigation
 */
export const videoChapters = pgTable(
  "video_chapter",
  {
    id: text("id").primaryKey(),
    videoId: text("video_id")
      .notNull()
      .references(() => videos.id, { onDelete: "cascade" }),

    timestamp: integer("timestamp").notNull(), // Start time in seconds
    endTimestamp: integer("end_timestamp"), // Optional end time
    title: text("title").notNull(),
    description: text("description"), // Optional longer description

    // Thumbnail for chapter preview (like YouTube hover)
    thumbnailUrl: text("thumbnail_url"),

    // Source tracking
    isAutoGenerated: boolean("is_auto_generated").default(true).notNull(),
    confidence: integer("confidence"), // AI confidence score 0-100

    // Ordering (for manual reordering via Drag & Drop UI)
    sortOrder: integer("sort_order").default(0).notNull(),

    createdAt: timestamp("created_at").defaultNow().notNull(),
    updatedAt: timestamp("updated_at")
      .defaultNow()
      .$onUpdate(() => new Date())
      .notNull(),

    deletedAt: timestamp("deleted_at"),
  },
  (table) => [
    index("chapter_videoId_idx").on(table.videoId),
    index("chapter_videoId_timestamp_idx").on(table.videoId, table.timestamp),
  ],
);

/**
 * AI-generated video summaries
 */
export const videoSummaries = pgTable(
  "video_summary",
  {
    id: text("id").primaryKey(),
    videoId: text("video_id")
      .notNull()
      .references(() => videos.id, { onDelete: "cascade" }),

    language: text("language").default("en").notNull(),

    // Different summary lengths
    shortSummary: text("short_summary"), // 1-2 sentences (Twitter style)
    mediumSummary: text("medium_summary"), // 1 paragraph (LinkedIn style)
    longSummary: text("long_summary"), // Full detailed summary (Blog style)

    // Key points/takeaways
    keyPoints: jsonb("key_points").default([]), // ["Point 1", "Point 2"]

    // Auto-generated tags/topics
    topics: jsonb("topics").default([]), // ["programming", "typescript", "tutorial"]

    // SEO-optimized description (Can be pushed to YouTube automatically)
    seoDescription: text("seo_description"),

    // Generation metadata
    provider: text("provider"), // 'openai', 'anthropic'
    modelUsed: text("model_used"), // 'gpt-4', 'claude-3'
    tokensUsed: integer("tokens_used"),

    createdAt: timestamp("created_at").defaultNow().notNull(),
    updatedAt: timestamp("updated_at")
      .defaultNow()
      .$onUpdate(() => new Date())
      .notNull(),

    deletedAt: timestamp("deleted_at"),
  },
  (table) => [
    index("summary_videoId_idx").on(table.videoId),
    index("summary_videoId_language_idx").on(table.videoId, table.language),
  ],
);

// ============================================
// RELATIONS
// ============================================

export const transcriptsRelations = relations(transcripts, ({ one, many }) => ({
  video: one(videos, {
    fields: [transcripts.videoId],
    references: [videos.id],
  }),
  embeddings: many(transcriptEmbeddings),
}));

export const transcriptEmbeddingsRelations = relations(
  transcriptEmbeddings,
  ({ one }) => ({
    transcript: one(transcripts, {
      fields: [transcriptEmbeddings.transcriptId],
      references: [transcripts.id],
    }),
    video: one(videos, {
      fields: [transcriptEmbeddings.videoId],
      references: [videos.id],
    }),
  }),
);

export const videoChaptersRelations = relations(videoChapters, ({ one }) => ({
  video: one(videos, {
    fields: [videoChapters.videoId],
    references: [videos.id],
  }),
}));

export const videoSummariesRelations = relations(videoSummaries, ({ one }) => ({
  video: one(videos, {
    fields: [videoSummaries.videoId],
    references: [videos.id],
  }),
}));
